{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database: Model-Fit\n",
    "===================\n",
    "\n",
    "This is a simple example of a model-fit which we wish to write to the database. This should simply output the\n",
    "results to the `.sqlite` database file."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pytest\n",
    "\n",
    "%matplotlib inline\n",
    "from pyprojroot import here\n",
    "workspace_path = str(here())\n",
    "%cd $workspace_path\n",
    "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
    "\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "os.environ[\"PYAUTOFIT_TEST_MODE\"] = \"1\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "from autoconf import conf\n",
    "\n",
    "conf.instance.push(new_path=path.join(cwd, \"config\", \"fit\"))\n",
    "\n",
    "import autofit as af\n",
    "import autolens as al\n",
    "import autolens.plot as aplt\n",
    "import slam"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset + Masking__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset_name = \"with_lens_light\"\n",
    "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
    "\n",
    "dataset = al.Imaging.from_fits(\n",
    "    data_path=path.join(dataset_path, \"data.fits\"),\n",
    "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
    "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
    "    pixel_scales=0.2,\n",
    ")\n",
    "\n",
    "mask = al.Mask2D.circular(\n",
    "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
    ")\n",
    "\n",
    "dataset = dataset.apply_mask(mask=mask)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Settings AutoFit__\n",
    "\n",
    "The settings of autofit, which controls the output paths, parallelization, database use, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "settings_search = af.SettingsSearch(\n",
    "    path_prefix=path.join(\"database\", \"scrape\", \"slam_pix\"),\n",
    "    number_of_cores=1,\n",
    "    session=None,\n",
    "    info={\"hi\": \"there\"},\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Redshifts__\n",
    "\n",
    "The redshifts of the lens and source galaxies, which are used to perform unit converions of the model and data (e.g. \n",
    "from arc-seconds to kiloparsecs, masses to solar masses, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "redshift_lens = 0.5\n",
    "redshift_source = 1.0\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SOURCE LP PIPELINE (with lens light)__\n",
    "\n",
    "The SOURCE LP PIPELINE (with lens light) uses three searches to initialize a robust model for the \n",
    "source galaxy's light, which in this example:\n",
    " \n",
    " - Uses a parametric `Sersic` bulge and `Exponential` disk with centres aligned for the lens\n",
    " galaxy's light.\n",
    " \n",
    " - Uses an `Isothermal` model for the lens's total mass distribution with an `ExternalShear`.\n",
    "\n",
    " Settings:\n",
    "\n",
    " - Mass Centre: Fix the mass profile centre to (0.0, 0.0) (this assumption will be relaxed in the MASS PIPELINE)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = al.AnalysisImaging(dataset=dataset)\n",
    "\n",
    "bulge = af.Model(al.lp_linear.Sersic)\n",
    "disk = af.Model(al.lp_linear.Exponential)\n",
    "# disk = af.Model(al.lp_linear.Sersic)\n",
    "bulge.centre = disk.centre\n",
    "\n",
    "source_lp_result = slam.source_lp.run(\n",
    "    settings_search=settings_search,\n",
    "    analysis=analysis,\n",
    "    lens_bulge=bulge,\n",
    "    lens_disk=disk,\n",
    "    mass=af.Model(al.mp.Isothermal),\n",
    "    shear=af.Model(al.mp.ExternalShear),\n",
    "    source_bulge=af.Model(al.lp_linear.Sersic),\n",
    "    redshift_lens=redshift_lens,\n",
    "    redshift_source=redshift_source,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SOURCE PIX PIPELINE (with lens light)__\n",
    "\n",
    "The SOURCE PIX PIPELINE (with lens light) uses two searches to initialize a robust model for the pixelization\n",
    "that reconstructs the source galaxy's light. It begins by fitting a `Delaunay` pixelization with `Constant` \n",
    "regularization, to set up the model and hyper images, and then:\n",
    "\n",
    " - Uses a `Delaunay` pixelization.\n",
    " - Uses an `AdaptiveBrightness` regularization.\n",
    " - Carries the lens redshift, source redshift and `ExternalShear` of the SOURCE LP PIPELINE through to the\n",
    " SOURCE PIX PIPELINE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = al.AnalysisImaging(\n",
    "    dataset=dataset,\n",
    "    adapt_image_maker=al.AdaptImageMaker(result=source_lp_result),\n",
    ")\n",
    "\n",
    "source_pix_result_1 = slam.source_pix.run_1(\n",
    "    settings_search=settings_search,\n",
    "    analysis=analysis,\n",
    "    source_lp_result=source_lp_result,\n",
    "    mesh_init=al.mesh.Delaunay,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SOURCE PIX PIPELINE 2 (with lens light)__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = al.AnalysisImaging(\n",
    "    dataset=dataset,\n",
    "    adapt_image_maker=al.AdaptImageMaker(result=source_pix_result_1),\n",
    "    settings_inversion=al.SettingsInversion(\n",
    "        image_mesh_min_mesh_pixels_per_pixel=3,\n",
    "        image_mesh_min_mesh_number=5,\n",
    "        image_mesh_adapt_background_percent_threshold=0.1,\n",
    "        image_mesh_adapt_background_percent_check=0.8,\n",
    "    ),\n",
    ")\n",
    "\n",
    "source_pix_result_2 = slam.source_pix.run_2(\n",
    "    settings_search=settings_search,\n",
    "    analysis=analysis,\n",
    "    source_lp_result=source_lp_result,\n",
    "    source_pix_result_1=source_pix_result_1,\n",
    "    image_mesh=al.image_mesh.Hilbert,\n",
    "    mesh=al.mesh.Delaunay,\n",
    "    regularization=al.reg.AdaptiveBrightnessSplit,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LIGHT LP PIPELINE__\n",
    "\n",
    "The LIGHT LP PIPELINE uses one search to fit a complex lens light model to a high level of accuracy, using the\n",
    "lens mass model and source light model fixed to the maximum log likelihood result of the SOURCE LP PIPELINE.\n",
    "In this example it:\n",
    "\n",
    " - Uses a parametric `Sersic` bulge and `Sersic` disk with centres aligned for the lens galaxy's \n",
    " light [Do not use the results of the SOURCE LP PIPELINE to initialize priors].\n",
    "\n",
    " - Uses an `Isothermal` model for the lens's total mass distribution [fixed from SOURCE LP PIPELINE].\n",
    "\n",
    " - Uses the `Sersic` model representing a bulge for the source's light [fixed from SOURCE LP PIPELINE].\n",
    "\n",
    " - Carries the lens redshift, source redshift and `ExternalShear` of the SOURCE PIPELINE through to the MASS \n",
    " PIPELINE [fixed values]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bulge = af.Model(al.lp_linear.Sersic)\n",
    "disk = af.Model(al.lp_linear.Exponential)\n",
    "bulge.centre = disk.centre\n",
    "\n",
    "analysis = al.AnalysisImaging(\n",
    "    dataset=dataset,\n",
    "    adapt_image_maker=al.AdaptImageMaker(result=source_pix_result_1),\n",
    ")\n",
    "\n",
    "light_result = slam.light_lp.run(\n",
    "    settings_search=settings_search,\n",
    "    analysis=analysis,\n",
    "    source_result_for_lens=source_pix_result_1,\n",
    "    source_result_for_source=source_pix_result_2,\n",
    "    lens_bulge=bulge,\n",
    "    lens_disk=disk,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MASS TOTAL PIPELINE (with lens light)__\n",
    "\n",
    "The MASS TOTAL PIPELINE (with lens light) uses one search to fits a complex lens mass model to a high level of accuracy, \n",
    "using the lens mass model and source model of the SOURCE PIPELINE to initialize the model priors and the lens light\n",
    "model of the LIGHT LP PIPELINE. In this example it:\n",
    "\n",
    " - Uses a parametric `Sersic` bulge and `Sersic` disk with centres aligned for the lens galaxy's \n",
    " light [fixed from LIGHT LP PIPELINE].\n",
    "\n",
    " - Uses an `PowerLaw` model for the lens's total mass distribution [priors initialized from SOURCE \n",
    " PARAMETRIC PIPELINE + centre unfixed from (0.0, 0.0)].\n",
    " \n",
    " - Uses the `Sersic` model representing a bulge for the source's light [priors initialized from SOURCE \n",
    " PARAMETRIC PIPELINE].\n",
    " \n",
    " - Carries the lens redshift, source redshift and `ExternalShear` of the SOURCE PIPELINE through to the MASS PIPELINE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = al.AnalysisImaging(\n",
    "    dataset=dataset, adapt_image_maker=al.AdaptImageMaker(result=source_pix_result_1)\n",
    ")\n",
    "\n",
    "multipole = af.Model(al.mp.PowerLawMultipole)\n",
    "multipole.m = 3\n",
    "\n",
    "mass_result = slam.mass_total.run(\n",
    "    settings_search=settings_search,\n",
    "    analysis=analysis,\n",
    "    source_result_for_lens=source_pix_result_1,\n",
    "    source_result_for_source=source_pix_result_2,\n",
    "    light_result=light_result,\n",
    "    mass=af.Model(al.mp.PowerLaw),\n",
    "    multipole_3=multipole,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Database__\n",
    "\n",
    "Add results to database."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from autofit.database.aggregator import Aggregator\n",
    "\n",
    "database_file = \"database_directory_slam_pix.sqlite\"\n",
    "\n",
    "try:\n",
    "    os.remove(path.join(\"output\", database_file))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "agg = Aggregator.from_database(database_file)\n",
    "agg.add_directory(directory=path.join(\"output\", \"database\", \"scrape\", \"slam_pix\"))\n",
    "\n",
    "assert len(agg) > 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Samples + Results__\n",
    "\n",
    "Make sure database + agg can be used."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\\n***********************\")\n",
    "print(\"****RESULTS TESTING****\")\n",
    "print(\"***********************\\n\")\n",
    "\n",
    "for samples in agg.values(\"samples\"):\n",
    "    print(samples.parameter_lists[0])\n",
    "\n",
    "mp_instances = [samps.median_pdf() for samps in agg.values(\"samples\")]\n",
    "print(mp_instances)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Queries__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\\n***********************\")\n",
    "print(\"****QUERIES TESTING****\")\n",
    "print(\"***********************\\n\")\n",
    "\n",
    "unique_tag = agg.search.unique_tag\n",
    "agg_query = agg.query(unique_tag == \"mass_sie__source_sersic__1\")\n",
    "samples_gen = agg_query.values(\"samples\")\n",
    "\n",
    "unique_tag = agg.search.unique_tag\n",
    "agg_query = agg.query(unique_tag == \"incorrect_name\")\n",
    "samples_gen = agg_query.values(\"samples\")\n",
    "\n",
    "name = agg.search.name\n",
    "agg_query = agg.query(name == \"database_example\")\n",
    "print(\"Total Queried Results via search name = \", len(agg_query), \"\\n\\n\")\n",
    "\n",
    "lens = agg.model.galaxies.lens\n",
    "agg_query = agg.query(lens.mass == al.mp.Isothermal)\n",
    "print(\"Total Samples Objects via `Isothermal` model query = \", len(agg_query), \"\\n\")\n",
    "\n",
    "source = agg.model.galaxies.source\n",
    "agg_query = agg.query(source.disk == None)\n",
    "print(\"Total Samples Objects via `Isothermal` model query = \", len(agg_query), \"\\n\")\n",
    "\n",
    "mass = agg.model.galaxies.lens.mass\n",
    "agg_query = agg.query((mass == al.mp.Isothermal) & (mass.einstein_radius > 1.0))\n",
    "\n",
    "print(\n",
    "    \"Total Samples Objects In Query `Isothermal and einstein_radius > 3.0` = \",\n",
    "    len(agg_query),\n",
    "    \"\\n\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Files__\n",
    "\n",
    "Check that all other files stored in database (e.g. model, search) can be loaded and used."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\\n***********************\")\n",
    "print(\"*****FILES TESTING*****\")\n",
    "print(\"***********************\\n\")\n",
    "\n",
    "for model in agg.values(\"model\"):\n",
    "    print(f\"\\n****Model Info (model)****\\n\\n{model.info}\")\n",
    "    assert model.info[0] == \"T\"\n",
    "\n",
    "for search in agg.values(\"search\"):\n",
    "    print(f\"\\n****Search (search)****\\n\\n{search}\")\n",
    "    assert \"[\" in search.paths.name\n",
    "\n",
    "for samples_summary in agg.values(\"samples_summary\"):\n",
    "    instance = samples_summary.max_log_likelihood()\n",
    "    print(f\"\\n****Max Log Likelihood (samples_summary)****\\n\\n{instance}\")\n",
    "    assert instance.galaxies.lens.mass.einstein_radius > 0.0\n",
    "\n",
    "for info in agg.values(\"info\"):\n",
    "    print(f\"\\n****Info****\\n\\n{info}\")\n",
    "    assert info[\"hi\"] == \"there\"\n",
    "\n",
    "for data in agg.values(\"dataset.data\"):\n",
    "    print(f\"\\n****Data (dataset.data)****\\n\\n{data}\")\n",
    "    assert isinstance(data[0], fits.PrimaryHDU)\n",
    "\n",
    "for noise_map in agg.values(\"dataset.noise_map\"):\n",
    "    print(f\"\\n****Noise Map (dataset.noise_map)****\\n\\n{noise_map}\")\n",
    "    assert isinstance(noise_map[0], fits.PrimaryHDU)\n",
    "\n",
    "for covariance in agg.values(\"covariance\"):\n",
    "    print(f\"\\n****Covariance (covariance)****\\n\\n{covariance}\")\n",
    "    assert covariance is not None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Aggregator Module__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\\n***********************\")\n",
    "print(\"***AGG MODULE TESTING***\")\n",
    "print(\"***********************\\n\\n\")\n",
    "\n",
    "agg = agg.query(agg.search.name == \"mass_total[1]\")\n",
    "\n",
    "tracer_agg = al.agg.TracerAgg(aggregator=agg)\n",
    "tracer_gen = tracer_agg.max_log_likelihood_gen_from()\n",
    "\n",
    "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.1)\n",
    "\n",
    "for tracer_list in tracer_gen:\n",
    "    # Only one `Analysis` so take first and only tracer.\n",
    "    tracer = tracer_list[0]\n",
    "\n",
    "    try:\n",
    "        tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
    "        tracer_plotter.figures_2d(convergence=True, potential=True)\n",
    "\n",
    "    except al.exc.ProfileException:\n",
    "        print(\"TracerAgg with linear light profiles raises correct ProfileException\")\n",
    "\n",
    "    assert tracer.galaxies[0].mass.einstein_radius > 0.0\n",
    "\n",
    "    print(\"TracerAgg Checked\")\n",
    "\n",
    "imaging_agg = al.agg.ImagingAgg(aggregator=agg)\n",
    "imaging_gen = imaging_agg.dataset_gen_from()\n",
    "\n",
    "for dataset_list in imaging_gen:\n",
    "    dataset = dataset_list[0]\n",
    "\n",
    "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
    "    dataset_plotter.subplot_dataset()\n",
    "\n",
    "    assert dataset.pixel_scales[0] > 0.0\n",
    "\n",
    "    print(\"ImagingAgg Checked\")\n",
    "\n",
    "fit_agg = al.agg.FitImagingAgg(\n",
    "    aggregator=agg,\n",
    "    settings_inversion=al.SettingsInversion(use_border_relocator=False),\n",
    ")\n",
    "fit_imaging_gen = fit_agg.max_log_likelihood_gen_from()\n",
    "\n",
    "for fit_list in fit_imaging_gen:\n",
    "    fit = fit_list[0]\n",
    "\n",
    "    fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
    "    fit_plotter.subplot_fit()\n",
    "\n",
    "    assert fit.tracer.galaxies[0].mass.einstein_radius > 0.0\n",
    "\n",
    "    print(\"FitImagingAgg Checked\")\n",
    "\n",
    "fit_imaging_gen = fit_agg.max_log_likelihood_gen_from()\n",
    "\n",
    "for fit_list in fit_imaging_gen:\n",
    "    fit = fit_list[0]\n",
    "\n",
    "    assert fit.adapt_images.model_image is not None\n",
    "\n",
    "    print(\"FitImagingAgg Adapt Images Checked\")\n",
    "\n",
    "os.environ[\"PYAUTOFIT_TEST_MODE\"] = \"0\"\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
